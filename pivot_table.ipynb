{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# split the events\n",
    "def get_event_list(x):\n",
    "    event_list = []\n",
    "    for i in x:\n",
    "        event_list.append(i)\n",
    "    return event_list\n",
    "\n",
    "# clean the data (for raw)\n",
    "def clean_data(raw):\n",
    "    df =\\\n",
    "    (\n",
    "        raw\n",
    "        .assign(\n",
    "            pic_age = lambda x: x.pic_age.str.replace('-','to').str.replace('+','plus').str.split(',').str[0], # get the first value in case of multiple pic_age\n",
    "            business_age = lambda x: x.business_age.str.replace('-','to').str.replace('+','plus').str.split(',').str[0], # get the first value in case of multiple business_age\n",
    "            surrounding_area_v2 = lambda x: x.surrounding_area_v2.str.replace('/','or').str.replace(' ',''),\n",
    "            edc_count = lambda x: x.edc_count.str.replace('-', 'to'),\n",
    "            mbanking_count = lambda x: x.mbanking_count.str.replace('-', 'to'),\n",
    "            count_employee = lambda x: pd.to_numeric(x.count_employee, errors='coerce'),\n",
    "            est_daily_customer = lambda x: pd.to_numeric(x.est_daily_customer, errors='coerce'),\n",
    "            count_trf = lambda x: pd.to_numeric(x.count_trf),\n",
    "            interest_to_loan_flag = lambda x: x.interest_to_loan_flag.str.replace('Ya', 'Tertarik')==\"Tertarik\", # as bool\n",
    "            cumulative_W3_core_NetRevenue = lambda x: pd.to_numeric(x.cumulative_W3_core_NetRevenue, errors='coerce'),\n",
    "            W3_retained_flag = lambda x: x.W3_retained_flag.fillna(0).astype(bool),\n",
    "            offline_acquired_date = lambda x: pd.to_datetime(x.offline_acquired_date),\n",
    "            # -- core\n",
    "            # F3D_core_TPU = lambda x: pd.to_numeric(x.F3D_core_TPU, errors='coerce'),\n",
    "            F3D_core_TPU_wd = lambda x: pd.to_numeric(x.F3D_core_TPU_wd, errors='coerce'),\n",
    "            # F3D_core_TPV = lambda x: pd.to_numeric(x.F3D_core_TPV, errors='coerce'),\n",
    "            F3D_core_TPV_wd = lambda x: pd.to_numeric(x.F3D_core_TPV_wd, errors='coerce'),\n",
    "            # F3D_core_NetRevenue = lambda x: pd.to_numeric(x.F3D_core_NetRevenue, errors='coerce'),  \n",
    "            F3D_core_NetRevenue_wd = lambda x: pd.to_numeric(x.F3D_core_NetRevenue_wd, errors='coerce'),\n",
    "            F3D_wallet_share = lambda x: pd.to_numeric(np.where(x.F3D_wallet_share > 1, None, x.F3D_wallet_share*100)),\n",
    "            # -- ppob\n",
    "            # F3D_ppob_TPU = lambda x: pd.to_numeric(x.F3D_ppob_TPU, errors='coerce'),\n",
    "            F3D_ppob_TPU_wd = lambda x: pd.to_numeric(x.F3D_ppob_TPU_wd, errors='coerce'),\n",
    "        )\n",
    "        # normalization\n",
    "        .assign(\n",
    "            count_employee = lambda x: x.count_employee.apply(np.log1p),\n",
    "            est_daily_customer = lambda x: x.est_daily_customer.apply(np.log1p),\n",
    "            count_trf = lambda x: pd.to_numeric(np.where(((x.count_trf > 5000) & (x.count_trf < 0)), None, x.count_trf.apply(np.log1p))),\n",
    "            # -- core\n",
    "            cumulative_W3_core_NetRevenue = lambda x: x.cumulative_W3_core_NetRevenue.apply(np.log1p),\n",
    "            # F3D_core_TPU = lambda x: x.F3D_core_TPU.apply(np.log1p).astype(float),\n",
    "            F3D_core_TPU_wd = lambda x: x.F3D_core_TPU_wd.apply(np.log1p).astype(float),\n",
    "            # F3D_core_TPV = lambda x: x.F3D_core_TPV.apply(np.log1p).astype(float),\n",
    "            F3D_core_TPV_wd = lambda x: x.F3D_core_TPV_wd.apply(np.log1p).astype(float),\n",
    "            # F3D_core_NetRevenue = lambda x: x.F3D_core_NetRevenue.apply(np.log1p),\n",
    "            F3D_core_NetRevenue_wd = lambda x: x.F3D_core_NetRevenue_wd.apply(np.log1p).astype(float),\n",
    "            F3D_wallet_share = lambda x: x.F3D_wallet_share.apply(np.log1p),\n",
    "            # -- ppob\n",
    "            # F3D_ppob_TPU = lambda x: x.F3D_ppob_TPU.apply(np.log1p).astype(float),\n",
    "            F3D_ppob_TPU_wd = lambda x: x.F3D_ppob_TPU_wd.apply(np.log1p).astype(float),\n",
    "        )\n",
    "        .apply(lambda x: (x==1).fillna(False).astype(bool) if x.name in raw.filter(like='flag').columns else x) #change all \"_flag\" columns to boolean\n",
    "    )\n",
    "\n",
    "    df =\\\n",
    "    (\n",
    "        df\n",
    "        .assign(\n",
    "            event_list = lambda x: x.event.apply(get_event_list)\n",
    "        )\n",
    "        .drop(columns=['event'])\n",
    "    )\n",
    "\n",
    "    # get all columns except for event_list\n",
    "    other_col = list(df.drop(columns='event_list').columns)\n",
    "\n",
    "    # split each item in each list into multiple columns and count their occurence\n",
    "    for i in sorted(set(sum(df['event_list'].tolist(),[]))):  \n",
    "        df[i] = df['event_list'].apply(lambda x: x.count(i) if i in x else np.NaN)\n",
    "\n",
    "    # get only the top 50 events\n",
    "    count = pd.Series(Counter(chain.from_iterable(df.event_list)))\n",
    "    event_col = (count.sort_values(ascending=False)[:100].index.tolist())\n",
    "\n",
    "    # # remove any event columns that are related to payment\n",
    "    event_col = [d for d in event_col if not any(True for w in ['payment', 'pembayaran', 'Payment', 'nulltest', 'ppob'] if w in d)]\n",
    "    col = event_col + other_col\n",
    "\n",
    "    return df[col]\n",
    "\n",
    "\n",
    "# # turn numeric columns into categorical\n",
    "def cat_num(x):\n",
    "    x2 = x[x > 0].describe()[4]\n",
    "    x3 = x[x > 0].describe()[5]\n",
    "    x4 = x[x > 0].describe()[6]\n",
    "    x5 = x[x > 0].describe()[7]\n",
    "    xcuts = pd.cut(x, bins=[0, x2, x3, x4, x5], include_lowest=True, duplicates='drop')\n",
    "    return xcuts\n",
    "\n",
    "# create pivot table\n",
    "def create_pivot(df, target_col, univariate=True):\n",
    "    for i in [col for col in df.select_dtypes(include=['float', 'int']).columns]:\n",
    "        df[i] = cat_num(df[i])\n",
    "    \n",
    "    if univariate:\n",
    "        for i in df.drop(columns=target_col):\n",
    "            pivot = df.pivot_table(index=i, values=target_col, aggfunc=['mean', 'sum', 'count'])\n",
    "            display(pivot)\n",
    "    else:\n",
    "        for i in list(itertools.combinations(df.drop(columns=target_col).columns, 2)):\n",
    "            pivot = df.pivot_table(index=[i[0], i[1]], values=target_col, aggfunc=['mean', 'sum', 'count'])\n",
    "            display(pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "res = (pd.read_csv('result/train_inference.csv')).append(pd.read_csv('result/test_inference.csv'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
